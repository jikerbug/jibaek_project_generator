{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_Chord_Estimator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+Fib3sDcqKEVckOsb0ugO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jikerbug/jibaek_project_generator/blob/master/Audio_Chord_Estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uwbPg7KnqYK",
        "colab_type": "text"
      },
      "source": [
        "# 개발 과정\n",
        "1. 인공지능 알고리즘 개념 및 원리 학습\n",
        "2. 코드 데이터 확보\n",
        "3. 딥러닝 모델 생성\n",
        "4. 딥러닝 모델 이용해 음악의 시간별 코드를 출력하는 프로그램 제작\n",
        "5. 시간별 코드를 보여주는 GUI 제작\n",
        "\n",
        "-\n",
        "\n",
        "##**인공지능 모델 1차 개발 일지 ( 2020-07-03 ~ 2020-07-12 )**\n",
        "\n",
        "### 1단계 : 인공지능 알고리즘 개념 및 원리 학습\n",
        "1. 2020-07-03 ~ 2020-07-09 : [Deep Learning (for Audio) with Python ](https://www.youtube.com/playlist?list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf) 동영상 강의를 통해 신경망, CNN, RNN, LSTM 개념 학습과 음악 장르 분류 실습 진행\n",
        "        오디오 신호에서 특성 값들을 추출해 신경망에 입력하여 음악장르를 예측하고 분류할 수 있다.\n",
        "\n",
        "\n",
        "### 2단계 : 코드(chord) 데이터 확보\n",
        "1. 2020-07-11 : [McGill-Billboard Songs and Chord Annotations\n",
        "Chord Recognition with Chromagram Data](https://www.kaggle.com/jacobvs/mcgill-billboard)에서 데이터 확보 //주의! : code 설명을 보기전 데이터의 구조 파악 필수\n",
        "        오디오 신호에서 추출한 Chromagram Data라는 24가지 특성 값을 통해 코드를 예측해보자\n",
        "\n",
        "### 3단계 : 딥러닝 모델 생성 및 학습(code 설명)\n",
        "1. 2020-07-11 ~ 2020-07-12 : 결과 : 48개의 코드 분류에 대해 약 31%의 정확도\n",
        "       (Amaj, Amin, Abmaj, Abmin, A#maj, A#min, Bmaj .... G#min, None(코드 없는 audio)) : 총 48개\n",
        "\n",
        "이상 1차 개발 내용은 아래의 코드에서 설명 : //주의! 설명이 다소 부정확할 수 있음\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXn934SBsT1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv # 데이터를 csv 파일에서 불러오기 위함\n",
        "import numpy as np # numpy array로 데이터를 변환하여 선형대수 연산을 하기 위함\n",
        "from sklearn.model_selection import train_test_split # 모델을 학습시킬 training data와 모델의 예측 성능을 검증할 validation data, test data를 나눠주기 위함\n",
        "import tensorflow.keras as keras # 인공지능 모델을 학습시키기 위함\n",
        "import matplotlib.pyplot as plt # 학습된 결과를 그래플 시각화하기 위함\n",
        "import os.path # 존재하지 않는 파일을 불러와서 오류가 나는 경우를 방지하기 위함 (by os.path.isfile(file_path))\n",
        "\n",
        "\n",
        "\n",
        "# 1. 코드 데이터와 를 불러오는 함수\n",
        "def load_data():\n",
        "\n",
        "    #####목표 : \n",
        "    #####1. metadata 폴더에 있는 chromagram 데이터와 해당 chromagram의 시간값 확보 (인공지능 모델의 input : chromagram 데이터. ex : [1.214124, 2.141215, 0.1321, 0, 0, 2.21312, 1.21412 ....] )\n",
        "    #####2. annotations 폴더에 있는 시간별 chord데이터를, chromagram의 시간값과 비교해 chromagram 데이터와 해당 chord값을 맵핑 (인공지능 모델의 output : chord 데이터. ex : 1(A:min이라는 뜻) )\n",
        "    #####3. input과 output을 인공지능 모델에 맞게 가공\n",
        "    \n",
        "    ##1. 중복해서 사용하는 파일 경로를 저장\n",
        "    path_metadata = './metadata/metadata'\n",
        "    csv_metadata = '/bothchroma.csv'\n",
        "    path_annotations = './annotations/annotations/'\n",
        "    csv_annotations = '/majmin.lab'\n",
        "    \n",
        "    input_metadata_chroma_list =[] # csv 파일들에서 Chromagram Data를 전부 받아올 리스트\n",
        "    output_annotations_chord_list =[] # lab 파일들(csv와 똑같이 취급 가능)에서 Chord Data를 전부 받아올 리스트\n",
        "    chord_time_segmentation = [] # 특정 음악의 특정 코드의 시작과 끝 시간을 담을 리스트\n",
        "\n",
        "    for folder_num in range(3,60): #데이터가 너무 많아서 일단은 0003 폴더 부터 0060 폴더 까지의 데이터로만 진행. \n",
        "\n",
        "        ##2. folder_num번째 폴더 파일 경로 저장\n",
        "        path_variable = ''\n",
        "        if(folder_num < 10):\n",
        "            path_variable = '/000' + str(folder_num)\n",
        "        elif(folder_num < 100):\n",
        "            path_variable = '/00' + str(folder_num)\n",
        "        elif(folder_num < 1000):\n",
        "            path_variable = '/0' + str(folder_num)\n",
        "        else:\n",
        "            path_variable = '/' + str(folder_num)\n",
        "        \n",
        "        \n",
        "        ##3. folder_num번째 폴더 파일 경로 저장()\n",
        "        complete_path_metadata = path_metadata + path_variable + csv_metadata # chromagram data\n",
        "        complete_path_annotations = path_annotations + path_variable + csv_annotations # chord data\n",
        "        \n",
        "        ##4. 파일이 존재하는지 체크\n",
        "        if(os.path.isfile(complete_path_metadata)):\n",
        "            pass\n",
        "        else:\n",
        "            continue #존재하지 않으면 아래에서 파일 open하는 과정 생략하고 위로 올라가서 for문 반복\n",
        "        \n",
        "        ##5. Chromagram Data를 불러와서 저장\n",
        "        with open(complete_path_metadata, 'r', encoding='utf-8') as f:\n",
        "            reader = csv.reader(f)\n",
        "            for segmented_metadata in reader:\n",
        "                input_metadata_chroma_list.append(segmented_metadata)\n",
        "\n",
        "       ##6. Chord Data를 불러와서 저장\n",
        "        with open(complete_path_annotations, 'r', encoding='utf-8') as f:\n",
        "            reader = csv.reader(f)\n",
        "            flag = 0\n",
        "            for segmented_chord_data in reader:\n",
        "                if(segmented_chord_data != []):\n",
        "                    output_annotations_chord_list.append(segmented_chord_data[0].split('\\t')[-1])\n",
        "                    segmentation =[]\n",
        "                    segmentation.append(segmented_chord_data[0].split('\\t')[0])\n",
        "                    segmentation.append(segmented_chord_data[0].split('\\t')[1])\n",
        "\n",
        "                    chord_time_segmentation.append(segmentation)\n",
        "                else:\n",
        "                    break\n",
        "                #\n",
        "                # flag +=1\n",
        "\n",
        "    ##7. Chord Data를 0~41까지의 int형 변수로 저장 (7(코드) * 6(코드의 variation) = 42) + none(코드 없는 값) : 48로 설정\n",
        "    #-> 48설정 이유 : 마지막 코드인 G#:min의 int변수 바로 다음인 42로 하기 보다는 결과값의 차이가 좀더 현저하게 나는 48로 설정해야 chord를 none으로 오판하는 일이 적을거라 생각)\n",
        "    retyped_chord_to_int_list = [] #int로 변환된 코드들을 저장\n",
        "    \n",
        "    root_chord_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
        "\n",
        "    type1 = ':maj'\n",
        "    type2 = ':min'\n",
        "    type3 = 'b:maj'\n",
        "    type4 = 'b:min'\n",
        "    type5 = '#:maj'\n",
        "    type6 = '#:min'\n",
        "    type_table = [type1, type2, type3, type4, type5, type6]\n",
        "\n",
        "    for chord in output_annotations_chord_list:\n",
        "        escape_flag = False\n",
        "        for chord_num, root_chord in enumerate(root_chord_list):\n",
        "            if (escape_flag):\n",
        "                break\n",
        "            for type_num, type in enumerate(type_table):\n",
        "                if (chord == (root_chord + type)):\n",
        "                    retyped_chord_to_int_list.append(chord_num * 4 + type_num)\n",
        "                    escape_flag = True\n",
        "                    break\n",
        "                elif (chord == 'N' or chord == 'X'):\n",
        "                    retyped_chord_to_int_list.append(48)\n",
        "                    escape_flag = True\n",
        "                    break\n",
        "\n",
        "\n",
        "    ##8. input_metadata_chroma_list의 시간 데이터를 아래의 리스트로 옮기는 데이터 분류작업\n",
        "    chroma_time_index_list = []\n",
        "    for chroma in input_metadata_chroma_list:\n",
        "        chroma_time_index_list.append(chroma[1])\n",
        "        del chroma[0]\n",
        "        del chroma[0]\n",
        "        #len(chroma) == 24\n",
        "\n",
        "\n",
        "    ##9. input_metadata_chroma_list의 string으로 되어있는 숫자값을 float으로 바꿔서 아래의 리스트에 넣어주기 (인공지능 모델에는 float 타입의 chromagram 데이터가 입력되어야 함!)\n",
        "    retyped_chroma_string_to_float = []\n",
        "    for chroma in input_metadata_chroma_list:\n",
        "        retyped_list = []\n",
        "        for value in chroma:\n",
        "            temp_list = []\n",
        "            temp_list.append(float(value))\n",
        "            retyped_list.append(temp_list)\n",
        "        retyped_chroma_string_to_float.append(retyped_list)\n",
        "\n",
        "\n",
        "    # print(retyped_chroma_string_to_float[0])\n",
        "    # print(chroma_time_index_list[0])\n",
        "    # print(chord_time_segmentation[0])\n",
        "    # print(retyped_chord_to_int_list[0])\n",
        "\n",
        "\n",
        "    ##10. chromagram의 시간값(from chroma_time_index_list)이 위치하는 시간대의 chord정보(from chord_time_segmentation(시간대), retyped_chord_to_int_list(chord)))를 아래의 리스트에 저장\n",
        "    chroma_time_related_chord_to_int_list = []\n",
        "    for chroma_time in chroma_time_index_list:\n",
        "        for time, chord in zip(chord_time_segmentation, retyped_chord_to_int_list):\n",
        "            start = time[0]\n",
        "            end = time[1]\n",
        "            #print(f'chroma_time:{chroma_time} start:{start} end:{end}')\n",
        "            if(float(chroma_time) >= float(start) and float(chroma_time) < float(end)):\n",
        "                chroma_time_related_chord_to_int_list.append(chord)\n",
        "                break\n",
        "\n",
        "\n",
        "    # 데이터 구조 파악을 위한 출력함수\n",
        "    # print(\"here\")\n",
        "    # print(len(chroma_time_related_chord_to_int_list))\n",
        "    # print(len(retyped_chroma_string_to_float))\n",
        "    # print(retyped_chroma_string_to_float[0])\n",
        "    # print(chroma_time_related_chord_to_int_list[0])\n",
        "    # for i in output_annotations_chord_list:\n",
        "    #     print(i)\n",
        "\n",
        "    # none 타입을 학습시키지 않기를 원하는 경우 사용할 코드\n",
        "    #n_deleted_output_annotations_chord_list = output_annotations_chord_list\n",
        "    # for chroma, chord in zip(input_metadata_chroma_list, output_annotations_chord_list):\n",
        "    #     print(\"test\" + chord)\n",
        "        \n",
        "    #     if chord == 'N':\n",
        "            \n",
        "    #         n_deleted_input_metadata_chroma_list.remove(chroma)\n",
        "    #         n_deleted_output_annotations_chord_list.remove(chord)\n",
        "    # print(len(retyped_chroma))\n",
        "    # print(len(input_metadata_chroma_list))\n",
        "\n",
        "    ##11. 인공지능 모델 학습을 위해 선형대수 연산이 가능하고 속도가 빠른 numpy array로 변환\n",
        "    X = np.array(retyped_chroma_string_to_float)\n",
        "    y = np.array(chroma_time_related_chord_to_int_list)\n",
        "\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2. 인공지능 모델 학습결과를 시각화하는 함수\n",
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "        :param history: Training history of model\n",
        "        :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 3. 인공지능 모델에 입력할 데이터셋을 test, training, validation으로 구분하는 함수\n",
        "def prepare_datasets(test_size, validation_size):\n",
        "\n",
        "\n",
        "    # load data\n",
        "    X, y= load_data()\n",
        "    print(\"Look at here\")\n",
        "    print(len(X))\n",
        "    print(len(y))\n",
        "\n",
        "    # create train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "\n",
        "    # create train/validation split\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # cnn과 달리 rnn에서는 이러한 3rd 차원이 필요 없다.\n",
        "    # X_train = X_train[..., np.newaxis] # 3d array -> (num_samples = 130, 13, 1)\n",
        "    # X_validation = X_validation[..., np.newaxis] # ... : 기존의 것들\n",
        "    # X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
        "\n",
        "\n",
        "# 4. 인공지능 모델을 구현하는 함수\n",
        "def build_model(input_shape):\n",
        "\n",
        "    # create RNN model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 2 LSTM layers\n",
        "    model.add(keras.layers.LSTM(256, input_shape=input_shape, return_sequences=True)) #256개의 레이어나 64개의 레이어나 정확도는 약 31%로 똑같았다...\n",
        "    # return_sequences : second lstm에서 이 시퀀스를 사용하고 싶기 떄문에 true로 한다.\n",
        "    model.add(keras.layers.LSTM(256))\n",
        "\n",
        "    # dense layer\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(49, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 5. 특정 데이터를 입력하여 결과값을 예측하는 함수\n",
        "def predict(model, X, y):\n",
        "\n",
        "    X = X[np.newaxis, ...]\n",
        "\n",
        "    # prediction = [[0.1, 0.2, ...]] # softmax의 결과물\n",
        "    prediction = model.predict(X) # X -> (1, 130, 13, 1)\n",
        "\n",
        "    # extract index with max value\n",
        "    predicted_index = np.argmax(prediction, axis=1) # [4]\n",
        "    print(\"Expected index: {}, Predicted index: {}\".format(y, predicted_index))\n",
        "\n",
        "# 6. 메인 실행함수\n",
        "if __name__ == \"__main__\":\n",
        "    pass\n",
        "    # create train, validation and test sets\n",
        "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
        "\n",
        "    # 데이터 구조 파악을 위한 print문\n",
        "    # print(len(y_train))\n",
        "    # print(y_train[0])\n",
        "    # print(y_test[0])\n",
        "    # print(y_validation[0])\n",
        "    # print(len(X_train))\n",
        "    # print(len(X_train[0]))\n",
        "    # print(X_train[0])\n",
        "    # print(X_test[0])\n",
        "    # print(X_validation[0])\n",
        "   \n",
        "    # create network\n",
        "    print(\"heoollo\")\n",
        "    print(X_train.shape[1],print(X_train.shape[1], ))\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2]) # (130, 13) (number of slices extract mfccs, mfccs)\n",
        "    model = build_model(input_shape)\n",
        "\n",
        "    # compile model\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)\n",
        "\n",
        "    #plot accuracy/error for training and validation\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate model on test set\n",
        "    test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "    print(\"Accuracy on test set is: {}\".format(test_accuracy))\n",
        "\n",
        "    # make prediction on a sample\n",
        "    X = X_test[100]\n",
        "    y = y_test[100]\n",
        "\n",
        "\n",
        "    predict(model, X, y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}